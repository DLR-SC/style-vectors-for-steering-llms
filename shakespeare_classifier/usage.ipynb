{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"notaphoenix/shakespeare_classifier_model\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"notaphoenix/shakespeare_classifier_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    label = model.config.id2label[predicted_class_id]\n",
    "    return (predicted_class_id, label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_gold(split=\"test\"):\n",
    "    ds = load_dataset(\"notaphoenix/shakespeare_dataset\", split=split)\n",
    "    predicted = [predict(x['text'])[0] for x in ds]\n",
    "    gold = [x['label'] for x in ds]\n",
    "    return predicted, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration notaphoenix--shakespeare_dataset-7d26b19ec4f377f7\n",
      "Found cached dataset parquet (/home/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--shakespeare_dataset-7d26b19ec4f377f7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8391608391608392, 'f1': 0.8270676691729323, 'precision': 0.8823529411764706, 'recall': 0.7783018867924528}\n",
      "macro-f1: 0.84\n",
      "{'precision': 0.8440690325717064}\n",
      "{'accuracy': 0.8391608391608392}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted, gold= get_pred_gold(split=\"validation\")\n",
    "\n",
    "print(\n",
    "    f\"{clf_metrics.compute(predicted, gold, average='macro')}\\n\"\n",
    "    f\"macro-f1: {round(f1_metric.compute(predictions=predicted, references=gold, average='macro')['f1'], 2)}\\n\"\n",
    "    f\"{precision.compute(predictions=predicted, references=gold, average='macro')}\\n\"\n",
    "    f\"{accuracy.compute(predictions=predicted, references=gold)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration notaphoenix--shakespeare_dataset-7d26b19ec4f377f7\n",
      "Found cached dataset parquet (/home/elba_ro/.cache/huggingface/datasets/notaphoenix___parquet/notaphoenix--shakespeare_dataset-7d26b19ec4f377f7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8666044776119403, 'f1': 0.8596663395485771, 'precision': 0.906832298136646, 'recall': 0.8171641791044776}\n",
      "macro-f1: 0.87\n",
      "{'precision': 0.8702242984740955}\n",
      "{'accuracy': 0.8666044776119403}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted, gold= get_pred_gold(split=\"test\")\n",
    "\n",
    "print(\n",
    "    f\"{clf_metrics.compute(predicted, gold, average='macro')}\\n\"\n",
    "    f\"macro-f1: {round(f1_metric.compute(predictions=predicted, references=gold, average='macro')['f1'], 2)}\\n\"\n",
    "    f\"{precision.compute(predictions=predicted, references=gold, average='macro')}\\n\"\n",
    "    f\"{accuracy.compute(predictions=predicted, references=gold)}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
